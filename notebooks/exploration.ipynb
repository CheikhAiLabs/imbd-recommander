{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f013a2b",
   "metadata": {},
   "source": [
    "# ðŸŽ¬ IMDb Recommender â€” Data Exploration & Validation\n",
    "\n",
    "This notebook walks through the complete pipeline with **data quality validation** at every stage:\n",
    "\n",
    "1. **Data Loading** â€” Load raw IMDb datasets\n",
    "2. **Data Validation (Pandera)** â€” Schema validation on raw & merged data\n",
    "3. **Exploration** â€” Understand distributions and quality\n",
    "4. **Feature Engineering** â€” Build model-ready features\n",
    "5. **Post-Feature Validation** â€” Validate the engineered dataset\n",
    "6. **Model Training** â€” Fit and validate the recommender\n",
    "7. **Recommendations** â€” Test with real queries (including tconst disambiguation)\n",
    "\n",
    "> Run `make train` first to download the data, or execute the cells below to explore interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072bb5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path for imports\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandera as pa\n",
    "\n",
    "plt.style.use(\"dark_background\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "\n",
    "from src.ingestion.loader import load_and_merge_datasets\n",
    "from src.features.engineering import run_feature_pipeline\n",
    "from src.models.recommender import ContentRecommender\n",
    "from src.validation.schemas import (\n",
    "    TitleBasicsSchema,\n",
    "    TitleRatingsSchema,\n",
    "    MergedDatasetSchema,\n",
    "    FilteredDatasetSchema,\n",
    "    FeatureEngineeredSchema,\n",
    "    validate_dataframe,\n",
    ")\n",
    "\n",
    "print(f\"âœ… Imports ready â€” Pandera v{pa.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5512e5",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data\n",
    "\n",
    "Load and merge `title.basics` and `title.ratings` from the raw data directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be2aa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = project_root / \"data\" / \"raw\"\n",
    "df = load_and_merge_datasets(raw_dir)\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f51ddc",
   "metadata": {},
   "source": [
    "## 2. Data Validation â€” Pandera Schema Check (Merged)\n",
    "\n",
    "Validate the merged DataFrame against `MergedDatasetSchema` to catch data quality issues early:\n",
    "- All required columns present with correct types\n",
    "- `tconst` starts with `\"tt\"` and is unique\n",
    "- `averageRating` âˆˆ [0, 10], `numVotes` > 0\n",
    "- No unexpected nulls in critical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff111540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate merged dataset against Pandera schema\n",
    "validate_dataframe(df, MergedDatasetSchema)\n",
    "\n",
    "# Quick data quality summary\n",
    "print(f\"\\nðŸ“‹ Data Quality Summary:\")\n",
    "print(f\"   Rows: {len(df):,}\")\n",
    "print(f\"   Unique tconst: {df['tconst'].nunique():,}\")\n",
    "print(f\"   Null genres: {df['genres'].isna().sum():,} ({df['genres'].isna().mean()*100:.1f}%)\")\n",
    "print(f\"   Null runtime: {df['runtimeMinutes'].isna().sum():,} ({df['runtimeMinutes'].isna().mean()*100:.1f}%)\")\n",
    "print(f\"   Rating range: [{df['averageRating'].min()}, {df['averageRating'].max()}]\")\n",
    "print(f\"   Votes range: [{df['numVotes'].min():,}, {df['numVotes'].max():,}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293538e7",
   "metadata": {},
   "source": [
    "## 3. Data Overview\n",
    "\n",
    "Explore data types, distributions, and quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ed8009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Title type distribution\n",
    "print(\"ðŸ“Š Title Type Distribution:\")\n",
    "print(df[\"titleType\"].value_counts().to_string())\n",
    "print(f\"\\nðŸ“ˆ Numerical Summary:\")\n",
    "df[[\"averageRating\", \"numVotes\", \"runtimeMinutes\", \"startYear\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a765b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genre frequency analysis\n",
    "genres_exploded = (\n",
    "    df[\"genres\"]\n",
    "    .dropna()\n",
    "    .str.split(\",\")\n",
    "    .explode()\n",
    "    .str.strip()\n",
    "    .value_counts()\n",
    "    .head(20)\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "genres_exploded.sort_values().plot(kind=\"barh\", ax=ax, color=\"#f5c518\", edgecolor=\"none\")\n",
    "ax.set_title(\"Top 20 Genres in IMDb Dataset\", fontsize=16, fontweight=\"bold\", color=\"#f5c518\")\n",
    "ax.set_xlabel(\"Count\", fontsize=12)\n",
    "ax.set_ylabel(\"\")\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Rating distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "axes[0].hist(df[\"averageRating\"].dropna(), bins=50, color=\"#3498db\", edgecolor=\"none\", alpha=0.8)\n",
    "axes[0].set_title(\"Rating Distribution\", fontsize=14, fontweight=\"bold\")\n",
    "axes[0].set_xlabel(\"Average Rating\")\n",
    "axes[1].hist(np.log10(df[\"numVotes\"].dropna() + 1), bins=50, color=\"#2ecc71\", edgecolor=\"none\", alpha=0.8)\n",
    "axes[1].set_title(\"Vote Count Distribution (log10)\", fontsize=14, fontweight=\"bold\")\n",
    "axes[1].set_xlabel(\"log10(numVotes)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7826e173",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "Run the full feature pipeline: filter â†’ encode genres â†’ scale numerics â†’ build feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16400400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed, feature_matrix, feature_names, artifacts = run_feature_pipeline(\n",
    "    df=df,\n",
    "    min_votes=500,\n",
    "    min_year=1970,\n",
    ")\n",
    "\n",
    "print(f\"\\nProcessed DataFrame: {df_processed.shape}\")\n",
    "print(f\"Feature matrix: {feature_matrix.shape}\")\n",
    "print(f\"Features: {feature_names}\")\n",
    "df_processed[[\"tconst\", \"primaryTitle\", \"genres\", \"averageRating\", \"numVotes\", \"startYear\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3058d4ab",
   "metadata": {},
   "source": [
    "## 5. Post-Feature Validation â€” Pandera Schema Check\n",
    "\n",
    "Validate the engineered DataFrame against `FeatureEngineeredSchema`:\n",
    "- Scaled features are in [0, 1]\n",
    "- Genre one-hot columns exist\n",
    "- No NaN in the feature matrix\n",
    "- Dataset has enough rows for meaningful recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ba8b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate feature-engineered dataset\n",
    "validate_dataframe(df_processed, FeatureEngineeredSchema)\n",
    "\n",
    "# Verify feature matrix integrity\n",
    "genre_cols = [c for c in df_processed.columns if c.startswith(\"genre_\")]\n",
    "scaled_cols = [c for c in df_processed.columns if c.endswith(\"_scaled\")]\n",
    "\n",
    "print(f\"\\nðŸ”¬ Feature Matrix Integrity:\")\n",
    "print(f\"   Shape: {feature_matrix.shape}\")\n",
    "print(f\"   dtype: {feature_matrix.dtype}\")\n",
    "print(f\"   NaN count: {np.isnan(feature_matrix).sum()}\")\n",
    "print(f\"   Scaled features ({len(scaled_cols)}): {scaled_cols}\")\n",
    "print(f\"   Genre features ({len(genre_cols)}): {genre_cols[:5]}{'...' if len(genre_cols) > 5 else ''}\")\n",
    "print(f\"   Value range: [{feature_matrix.min():.4f}, {feature_matrix.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67954f4",
   "metadata": {},
   "source": [
    "## 6. Model Training & Validation\n",
    "\n",
    "Fit the `ContentRecommender` and test with well-known titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9849392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the recommender\n",
    "model = ContentRecommender()\n",
    "model.fit(\n",
    "    feature_matrix=feature_matrix,\n",
    "    tconst_ids=df_processed[\"tconst\"].tolist(),\n",
    "    titles=df_processed[\"primaryTitle\"].tolist(),\n",
    ")\n",
    "\n",
    "# Test with Inception\n",
    "print(\"ðŸŽ¬ Recommendations for 'Inception':\\n\")\n",
    "recs = model.recommend(\"Inception\", top_k=10)\n",
    "pd.DataFrame(recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf6f5b1",
   "metadata": {},
   "source": [
    "## 7. Explore More Recommendations\n",
    "\n",
    "Test with various popular titles and demonstrate **tconst disambiguation** for duplicate title names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7706e98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_titles = [\"The Dark Knight\", \"Breaking Bad\", \"Pulp Fiction\", \"The Matrix\", \"Stranger Things\"]\n",
    "\n",
    "for title in test_titles:\n",
    "    try:\n",
    "        recs = model.recommend(title, top_k=5)\n",
    "        print(f\"\\nðŸŽ¬ Top 5 for '{title}':\")\n",
    "        for r in recs:\n",
    "            print(f\"   #{r['rank']} {r['title']} (score: {r['similarity_score']:.4f})\")\n",
    "    except ValueError as e:\n",
    "        print(f\"\\nâš ï¸  {title}: {e}\")\n",
    "\n",
    "# --- tconst disambiguation ---\n",
    "# When multiple titles share the same name (e.g., \"Parasite\"),\n",
    "# use the tconst ID to select the exact one you want.\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ðŸ” tconst Disambiguation Demo:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Find all titles named \"Parasite\"\n",
    "parasite_matches = df_processed[df_processed[\"primaryTitle\"] == \"Parasite\"]\n",
    "if len(parasite_matches) > 0:\n",
    "    print(f\"\\nFound {len(parasite_matches)} titles named 'Parasite':\")\n",
    "    for _, row in parasite_matches.iterrows():\n",
    "        print(f\"   {row['tconst']} â€” {row['primaryTitle']} ({int(row['startYear'])})\")\n",
    "\n",
    "    # Recommend using the specific 2019 Parasite via tconst\n",
    "    target_tconst = parasite_matches.iloc[0][\"tconst\"]\n",
    "    recs = model.recommend(\"Parasite\", top_k=5, tconst=target_tconst)\n",
    "    print(f\"\\nðŸŽ¬ Recommendations for 'Parasite' (tconst={target_tconst}):\")\n",
    "    for r in recs:\n",
    "        print(f\"   #{r['rank']} {r['title']} (score: {r['similarity_score']:.4f})\")\n",
    "else:\n",
    "    print(\"   'Parasite' not found in dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c964e02b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates the full IMDb Recommender pipeline with **data validation at every stage**:\n",
    "\n",
    "| Stage | What | Validation |\n",
    "|:-----:|------|-----------|\n",
    "| 1 | **Data Loading** â€” Merged 2 IMDb datasets with proper null handling | â€” |\n",
    "| 2 | **Pandera Validation** â€” Schema check on merged dataset | `MergedDatasetSchema` |\n",
    "| 3 | **Exploration** â€” Analyzed genre, rating, and vote distributions | â€” |\n",
    "| 4 | **Feature Engineering** â€” Genre encoding + numerical scaling â†’ 30-D feature matrix | â€” |\n",
    "| 5 | **Post-Feature Validation** â€” Schema check on engineered data | `FeatureEngineeredSchema` |\n",
    "| 6 | **Model Training** â€” Content-based recommender with cosine similarity | Built-in `_validate_model()` |\n",
    "| 7 | **Recommendations** â€” Tested with popular titles + tconst disambiguation | â€” |\n",
    "\n",
    "**Available Pandera schemas** (in `src/validation/schemas.py`):\n",
    "- `TitleBasicsSchema` â€” raw `title.basics.tsv`\n",
    "- `TitleRatingsSchema` â€” raw `title.ratings.tsv`\n",
    "- `MergedDatasetSchema` â€” merged basics + ratings\n",
    "- `FilteredDatasetSchema` â€” after title type / votes / year filtering\n",
    "- `FeatureEngineeredSchema` â€” final model-ready DataFrame\n",
    "\n",
    "To serve this model via API: `make api`\n",
    "To launch the UI: `make ui`\n",
    "To view MLflow experiments: `make mlflow`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
